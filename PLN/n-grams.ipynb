{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b37b072",
   "metadata": {},
   "source": [
    "# Texto to N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976131ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'an', 'IA', 'student.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n_gram(text, n_grams=1):\n",
    "    sequence = text.split()\n",
    "    n_gram_list = []\n",
    "    for i in range(len(sequence) - n_grams + 1):\n",
    "        n_gram_list.append(' '.join(sequence[i:i + n_grams]))\n",
    "    return n_gram_list\n",
    "\n",
    "n_gram(\"I am an IA student.\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796ce87",
   "metadata": {},
   "source": [
    "### Train a n-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ce6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/matheus/miniconda3/envs/NLP/lib/python3.14/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /home/matheus/miniconda3/envs/NLP/lib/python3.14/site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /home/matheus/miniconda3/envs/NLP/lib/python3.14/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/matheus/miniconda3/envs/NLP/lib/python3.14/site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in /home/matheus/miniconda3/envs/NLP/lib/python3.14/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f26435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/matheus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/matheus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/matheus/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contextlib\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, gutenberg\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61107900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text: the fogge and filthie ayre.\n",
      "\n",
      "Exeunt.\n",
      "\n",
      "\n",
      "Scena Secunda.\n",
      "\n",
      "Alarum within. Enter King Malcome, Donalbaine\n",
      "Normalized Text: fogge filthie ayre exeunt scena secunda alarum within enter king malcome donalbaine\n"
     ]
    }
   ],
   "source": [
    "stop_words_en = set(stopwords.words('english'))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_punctuation(text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = \" \".join(text.split())\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens =  [word for word in tokens if word not in stop_words_en and word.isalpha()] \n",
    "    normalized_text = \" \".join(tokens)\n",
    "    return normalized_text\n",
    "\n",
    "fileid = 'shakespeare-macbeth.txt'\n",
    "raw_text = gutenberg.raw(fileid)\n",
    "print(\"Raw Text:\", raw_text[500:600])\n",
    "normalized_text = normalize_text(raw_text[500:600])\n",
    "print(\"Normalized Text:\", normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61142b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class NGramModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.ngrams = []\n",
    "        self.context = []\n",
    "        self.vocab = set(['<SOT>', '<EOT>'])\n",
    "        self.tokenized_corpus = []\n",
    "\n",
    "    def tokenizer(self, text):\n",
    "        return word_tokenize(text) \n",
    "\n",
    "    def add_special_tokens(self, tokens):\n",
    "        return ['<SOT>'] + tokens + ['<EOT>']\n",
    "    \n",
    "    def add_padding(self, tokens):\n",
    "        return ['<SOT>']*(self.n - 1) + tokens + ['<EOT>']\n",
    "\n",
    "    def create_ngrams(self):\n",
    "        for i in range(self.n-1, len(self.tokenized_corpus)):\n",
    "            self.ngrams.append(' '.join(self.tokenized_corpus[i - self.n + 1:i + 1]))\n",
    "            self.context.append(' '.join(self.tokenized_corpus[i - self.n + 1:i]))\n",
    "\n",
    "    def create_vocab(self):\n",
    "        self.vocab.update(set(self.tokenized_corpus))\n",
    "\n",
    "    def calculate_probabilities_of_vocab(self, token_sequence):\n",
    "        context = ' '.join(token_sequence[-self.n+1:])\n",
    "        context_frequency = self.tokenized_corpus.count(context)\n",
    "        context_and_vocab_candidates = [f\"{context} {word}\" for word in self.vocab]\n",
    "        context_and_vocab_candidates_frequency = [self.ngrams.count(candidate) for candidate in context_and_vocab_candidates]\n",
    "        probabilities = []\n",
    "        for cadidate in context_and_vocab_candidates_frequency:\n",
    "            probabilities.append(cadidate / context_frequency if context_frequency > 0 else 0)\n",
    "        return probabilities\n",
    "    \n",
    "    def predict_next_token(self, token_sequence):\n",
    "        probabilities = self.calculate_probabilities_of_vocab(token_sequence)\n",
    "        idx_max = probabilities.index(max(probabilities))\n",
    "        return list(self.vocab)[idx_max], probabilities[idx_max]\n",
    "\n",
    "    def generate_text(self, seed_text, max_length=20):\n",
    "        tokenized_seed = self.tokenizer(seed_text)\n",
    "        generated_tokens = tokenized_seed.copy()\n",
    "        for _ in range(max_length):\n",
    "            next_token, _ = self.predict_next_token(generated_tokens)\n",
    "            generated_tokens.append(next_token)\n",
    "            if next_token == '<EOT>':\n",
    "                break\n",
    "        return ' '.join(generated_tokens)\n",
    "    \n",
    "    def train(self, text):\n",
    "        self.tokenized_corpus = self.add_special_tokens(self.tokenizer(text))\n",
    "        self.create_ngrams()\n",
    "        self.create_vocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e78acb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tragedie macbeth william shakespeare actus primus scoena prima enter macbeth macb haue done'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NGramModel(2)\n",
    "\n",
    "normalized_text = normalize_text(raw_text)\n",
    "model.train(text=normalized_text)\n",
    "model.predict_next_token(model.tokenizer(\"tragedie macbeth william\"))\n",
    "model.generate_text(\"tragedie macbeth william\", max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8a047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
